{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Welcome to the Pandas tutorial! **Pandas** is the most popular Python library for data analysis and manipulation. If NumPy is great for numerical computations, Pandas is perfect for working with structured data (like spreadsheets or databases).\n",
    "\n",
    "## What is Pandas?\n",
    "\n",
    "Pandas provides:\n",
    "- **DataFrames** - Think of them as powerful spreadsheets in Python\n",
    "- **Series** - One-dimensional labeled arrays\n",
    "- **Easy data I/O** - Read/write CSV, Excel, SQL databases, and more\n",
    "- **Data cleaning and transformation** - Handle missing data, merge datasets, group and aggregate\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "1. **Series vs DataFrame** - Understanding the two main data structures\n",
    "2. **Creating data** - From lists, dictionaries, and other sources\n",
    "3. **Reading/Writing CSV files** - Loading and saving data\n",
    "4. **Basic operations** - Describe, indexing, creating columns\n",
    "5. **Combining DataFrames** - Merge and concatenate\n",
    "6. **Advanced operations** - GroupBy and aggregations\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Importing Pandas\n",
    "\n",
    "The standard convention is to import pandas as `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check pandas version\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Series vs DataFrame\n",
    "\n",
    "Pandas has two main data structures:\n",
    "\n",
    "### Series - 1D Labeled Array\n",
    "\n",
    "A **Series** is like a column in a spreadsheet. It's a one-dimensional array with labels (called an **index**).\n",
    "\n",
    "Think of it as:\n",
    "- A single column from a spreadsheet\n",
    "- A NumPy array with labels\n",
    "- A dictionary with ordered keys\n",
    "\n",
    "### DataFrame - 2D Labeled Table\n",
    "\n",
    "A **DataFrame** is like an entire spreadsheet. It's a two-dimensional table with labeled rows and columns.\n",
    "\n",
    "Think of it as:\n",
    "- An Excel spreadsheet\n",
    "- A SQL table\n",
    "- A collection of Series (each column is a Series)\n",
    "\n",
    "Let's see them in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATING A SERIES =====\n",
    "# From a list (index is automatically 0, 1, 2, ...)\n",
    "temperatures = pd.Series([20, 22, 19, 23, 21])\n",
    "print(\"Series with default index:\")\n",
    "print(temperatures)\n",
    "print(f\"\\nType: {type(temperatures)}\")\n",
    "\n",
    "# Series with custom index\n",
    "temperatures_labeled = pd.Series(\n",
    "    [20, 22, 19, 23, 21],\n",
    "    index=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    ")\n",
    "print(\"\\nSeries with custom index:\")\n",
    "print(temperatures_labeled)\n",
    "\n",
    "# From a dictionary (keys become the index)\n",
    "grades = pd.Series({\n",
    "    'Alice': 85,\n",
    "    'Bob': 92,\n",
    "    'Carol': 78,\n",
    "    'David': 95\n",
    "})\n",
    "print(\"\\nSeries from dictionary:\")\n",
    "print(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Properties and Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SERIES PROPERTIES =====\n",
    "print(\"--- Series Properties ---\")\n",
    "print(f\"Values: {grades.values}\")       # NumPy array of values\n",
    "print(f\"Index: {grades.index}\")         # Index labels\n",
    "print(f\"Size: {grades.size}\")           # Number of elements\n",
    "print(f\"Data type: {grades.dtype}\")\n",
    "\n",
    "# ===== ACCESSING ELEMENTS =====\n",
    "print(\"\\n--- Accessing Elements ---\")\n",
    "print(f\"Alice's grade: {grades['Alice']}\")  # By label\n",
    "print(f\"First grade: {grades.iloc[0]}\")     # By position\n",
    "\n",
    "# ===== BASIC OPERATIONS =====\n",
    "print(\"\\n--- Basic Operations ---\")\n",
    "print(f\"Mean: {grades.mean():.2f}\")\n",
    "print(f\"Max: {grades.max()}\")\n",
    "print(f\"Min: {grades.min()}\")\n",
    "print(f\"Sum: {grades.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATING A DATAFRAME FROM DICTIONARY =====\n",
    "# Keys become column names, values are the data\n",
    "students = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Carol', 'David'],\n",
    "    'Age': [20, 21, 19, 22],\n",
    "    'Grade': [85, 92, 78, 95],\n",
    "    'City': ['Madrid', 'Barcelona', 'Madrid', 'Valencia']\n",
    "})\n",
    "\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(students)\n",
    "print(f\"\\nType: {type(students)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATING A DATAFRAME FROM LIST OF LISTS =====\n",
    "data = [\n",
    "    ['Alice', 20, 85, 'Madrid'],\n",
    "    ['Bob', 21, 92, 'Barcelona'],\n",
    "    ['Carol', 19, 78, 'Madrid'],\n",
    "    ['David', 22, 95, 'Valencia']\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age', 'Grade', 'City'])\n",
    "print(\"DataFrame from list of lists:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATING A DATAFRAME FROM LIST OF DICTIONARIES =====\n",
    "data_dicts = [\n",
    "    {'Name': 'Alice', 'Age': 20, 'Grade': 85, 'City': 'Madrid'},\n",
    "    {'Name': 'Bob', 'Age': 21, 'Grade': 92, 'City': 'Barcelona'},\n",
    "    {'Name': 'Carol', 'Age': 19, 'Grade': 78, 'City': 'Madrid'},\n",
    "    {'Name': 'David', 'Age': 22, 'Grade': 95, 'City': 'Valencia'}\n",
    "]\n",
    "\n",
    "df2 = pd.DataFrame(data_dicts)\n",
    "print(\"DataFrame from list of dictionaries:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATING A DATAFRAME FROM NUMPY ARRAY =====\n",
    "np_data = np.array([\n",
    "    [85, 20],\n",
    "    [92, 21],\n",
    "    [78, 19],\n",
    "    [95, 22]\n",
    "])\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "    np_data,\n",
    "    columns=['Grade', 'Age'],\n",
    "    index=['Alice', 'Bob', 'Carol', 'David']\n",
    ")\n",
    "print(\"DataFrame from NumPy array:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATAFRAME PROPERTIES =====\n",
    "print(\"--- DataFrame Properties ---\")\n",
    "print(f\"Shape (rows, columns): {students.shape}\")\n",
    "print(f\"Number of rows: {len(students)}\")\n",
    "print(f\"Number of columns: {len(students.columns)}\")\n",
    "print(f\"Column names: {list(students.columns)}\")\n",
    "print(f\"Index: {list(students.index)}\")\n",
    "print(f\"Size (total elements): {students.size}\")\n",
    "\n",
    "print(\"\\n--- Data Types ---\")\n",
    "print(students.dtypes)\n",
    "\n",
    "print(\"\\n--- Info (summary) ---\")\n",
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences: Series vs DataFrame\n",
    "\n",
    "| Feature | Series | DataFrame |\n",
    "|---------|--------|----------|\n",
    "| Dimensions | 1D (column) | 2D (table) |\n",
    "| Analogy | One column in Excel | Entire Excel sheet |\n",
    "| Index | Yes (row labels) | Yes (row labels) |\n",
    "| Columns | No | Yes (column labels) |\n",
    "| Access column | N/A | `df['column_name']` returns a Series |\n",
    "| Use case | Single variable | Multiple variables |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RELATIONSHIP BETWEEN SERIES AND DATAFRAME =====\n",
    "# A DataFrame is a collection of Series!\n",
    "print(\"Extract a column (returns a Series):\")\n",
    "ages = students['Age']\n",
    "print(ages)\n",
    "print(f\"\\nType: {type(ages)}\")\n",
    "\n",
    "# Each column is a Series\n",
    "print(\"\\nGrade column:\")\n",
    "print(students['Grade'])\n",
    "print(f\"Type: {type(students['Grade'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Practice Exercise: Series and DataFrame Creation\n",
    "\n",
    "1. Create a Series with the temperatures for 7 days: [22, 24, 19, 23, 25, 21, 20]. Use day names as index.\n",
    "2. Create a DataFrame with information about 3 books:\n",
    "   - Columns: 'Title', 'Author', 'Year', 'Pages'\n",
    "   - Use any books you like\n",
    "3. Extract the 'Year' column from your DataFrame (it should be a Series)\n",
    "4. Print the shape and column names of your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading and Writing CSV Files\n",
    "\n",
    "One of Pandas' most useful features is reading and writing data files. Let's focus on CSV (Comma-Separated Values) files, the most common format.\n",
    "\n",
    "### Writing a CSV File\n",
    "\n",
    "First, let's create a DataFrame and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATE SAMPLE DATA =====\n",
    "employees = pd.DataFrame({\n",
    "    'EmployeeID': [101, 102, 103, 104, 105],\n",
    "    'Name': ['Alice Johnson', 'Bob Smith', 'Carol Davis', 'David Wilson', 'Eve Brown'],\n",
    "    'Department': ['Sales', 'IT', 'Sales', 'HR', 'IT'],\n",
    "    'Salary': [50000, 65000, 52000, 48000, 70000],\n",
    "    'YearsExperience': [3, 5, 4, 2, 6]\n",
    "})\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== WRITE TO CSV =====\n",
    "# Basic write\n",
    "employees.to_csv('employees.csv', index=False)\n",
    "print(\"âœ“ Saved to 'employees.csv' (without index)\")\n",
    "\n",
    "# Write with index\n",
    "employees.to_csv('employees_with_index.csv', index=True)\n",
    "print(\"âœ“ Saved to 'employees_with_index.csv' (with index)\")\n",
    "\n",
    "# Write only specific columns\n",
    "employees.to_csv('employees_partial.csv', columns=['Name', 'Department'], index=False)\n",
    "print(\"âœ“ Saved to 'employees_partial.csv' (only Name and Department)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a CSV File\n",
    "\n",
    "Now let's read the CSV files we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== READ FROM CSV =====\n",
    "# Basic read\n",
    "df_read = pd.read_csv('employees.csv')\n",
    "print(\"Read from 'employees.csv':\")\n",
    "print(df_read)\n",
    "print(f\"\\nShape: {df_read.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== USEFUL READ_CSV PARAMETERS =====\n",
    "\n",
    "# Read with specific column as index\n",
    "df_indexed = pd.read_csv('employees.csv', index_col='EmployeeID')\n",
    "print(\"Read with EmployeeID as index:\")\n",
    "print(df_indexed)\n",
    "\n",
    "# Read only specific columns\n",
    "df_partial = pd.read_csv('employees.csv', usecols=['Name', 'Salary'])\n",
    "print(\"\\nRead only Name and Salary columns:\")\n",
    "print(df_partial)\n",
    "\n",
    "# Read first N rows\n",
    "df_sample = pd.read_csv('employees.csv', nrows=3)\n",
    "print(\"\\nRead only first 3 rows:\")\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing Data\n",
    "\n",
    "After reading a file, you'll want to preview the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PREVIEWING DATA =====\n",
    "# First few rows\n",
    "print(\"First 3 rows (head):\")\n",
    "print(df_read.head(3))\n",
    "\n",
    "# Last few rows\n",
    "print(\"\\nLast 2 rows (tail):\")\n",
    "print(df_read.tail(2))\n",
    "\n",
    "# Random sample\n",
    "print(\"\\nRandom 2 rows (sample):\")\n",
    "print(df_read.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Pandas Functionality\n",
    "\n",
    "### The describe() Method\n",
    "\n",
    "The `describe()` method provides a statistical summary of numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DESCRIBE METHOD =====\n",
    "print(\"Statistical summary:\")\n",
    "print(employees.describe())\n",
    "\n",
    "# Describe all columns (including non-numeric)\n",
    "print(\"\\nDescribe all columns:\")\n",
    "print(employees.describe(include='all'))\n",
    "\n",
    "# Describe only object (string) columns\n",
    "print(\"\\nDescribe only object columns:\")\n",
    "print(employees.describe(include='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== STATISTICAL METHODS =====\n",
    "print(\"--- Salary Statistics ---\")\n",
    "print(f\"Mean salary: ${employees['Salary'].mean():,.2f}\")\n",
    "print(f\"Median salary: ${employees['Salary'].median():,.2f}\")\n",
    "print(f\"Min salary: ${employees['Salary'].min():,.2f}\")\n",
    "print(f\"Max salary: ${employees['Salary'].max():,.2f}\")\n",
    "print(f\"Std deviation: ${employees['Salary'].std():,.2f}\")\n",
    "print(f\"Sum of salaries: ${employees['Salary'].sum():,.2f}\")\n",
    "\n",
    "# Count, unique, value_counts\n",
    "print(\"\\n--- Department Info ---\")\n",
    "print(f\"Total entries: {employees['Department'].count()}\")\n",
    "print(f\"Unique departments: {employees['Department'].nunique()}\")\n",
    "print(f\"Unique values: {employees['Department'].unique()}\")\n",
    "print(\"\\nValue counts:\")\n",
    "print(employees['Department'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Indexing and Selection\n",
    "\n",
    "Pandas provides multiple ways to select data. Understanding these is crucial!\n",
    "\n",
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SELECTING COLUMNS =====\n",
    "# Single column (returns a Series)\n",
    "names = employees['Name']\n",
    "print(\"Names column (Series):\")\n",
    "print(names)\n",
    "print(f\"Type: {type(names)}\")\n",
    "\n",
    "# Multiple columns (returns a DataFrame)\n",
    "subset = employees[['Name', 'Salary']]\n",
    "print(\"\\nName and Salary columns (DataFrame):\")\n",
    "print(subset)\n",
    "print(f\"Type: {type(subset)}\")\n",
    "\n",
    "# Dot notation (only works for column names without spaces)\n",
    "salaries = employees.Salary\n",
    "print(\"\\nUsing dot notation:\")\n",
    "print(salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc vs iloc - Label vs Position Based Indexing\n",
    "\n",
    "This is one of the most important concepts in Pandas:\n",
    "\n",
    "- **`loc`** - Label-based indexing (uses row/column names)\n",
    "- **`iloc`** - Position-based indexing (uses integer positions, like NumPy)\n",
    "\n",
    "**Format**: `df.loc[rows, columns]` or `df.iloc[rows, columns]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LOC - LABEL BASED =====\n",
    "print(\"--- Using loc (label-based) ---\")\n",
    "\n",
    "# Single row by index label\n",
    "print(\"Row with index 0:\")\n",
    "print(employees.loc[0])\n",
    "\n",
    "# Multiple rows\n",
    "print(\"\\nRows 0 to 2:\")\n",
    "print(employees.loc[0:2])  # NOTE: With loc, end is INCLUDED!\n",
    "\n",
    "# Specific row and column\n",
    "print(\"\\nRow 1, Name column:\")\n",
    "print(employees.loc[1, 'Name'])\n",
    "\n",
    "# Multiple rows and columns\n",
    "print(\"\\nRows 0-2, Name and Salary columns:\")\n",
    "print(employees.loc[0:2, ['Name', 'Salary']])\n",
    "\n",
    "# All rows, specific columns\n",
    "print(\"\\nAll rows, Department and Salary:\")\n",
    "print(employees.loc[:, ['Department', 'Salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ILOC - POSITION BASED =====\n",
    "print(\"--- Using iloc (position-based) ---\")\n",
    "\n",
    "# First row (position 0)\n",
    "print(\"First row:\")\n",
    "print(employees.iloc[0])\n",
    "\n",
    "# Multiple rows\n",
    "print(\"\\nRows 0 to 2:\")\n",
    "print(employees.iloc[0:3])  # NOTE: With iloc, end is EXCLUDED (like Python slicing)\n",
    "\n",
    "# Specific position\n",
    "print(\"\\nRow 1, column 1 (second row, second column):\")\n",
    "print(employees.iloc[1, 1])\n",
    "\n",
    "# Multiple rows and columns by position\n",
    "print(\"\\nFirst 3 rows, first 2 columns:\")\n",
    "print(employees.iloc[0:3, 0:2])\n",
    "\n",
    "# Last row\n",
    "print(\"\\nLast row:\")\n",
    "print(employees.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing (Filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== BOOLEAN INDEXING =====\n",
    "# Filter rows based on conditions\n",
    "\n",
    "# Salary greater than 55000\n",
    "high_earners = employees[employees['Salary'] > 55000]\n",
    "print(\"Employees with salary > $55,000:\")\n",
    "print(high_earners)\n",
    "\n",
    "# Department equals 'IT'\n",
    "it_dept = employees[employees['Department'] == 'IT']\n",
    "print(\"\\nIT Department employees:\")\n",
    "print(it_dept)\n",
    "\n",
    "# Multiple conditions (AND)\n",
    "experienced_it = employees[(employees['Department'] == 'IT') & (employees['YearsExperience'] >= 5)]\n",
    "print(\"\\nIT employees with 5+ years experience:\")\n",
    "print(experienced_it)\n",
    "\n",
    "# Multiple conditions (OR)\n",
    "sales_or_hr = employees[(employees['Department'] == 'Sales') | (employees['Department'] == 'HR')]\n",
    "print(\"\\nSales or HR employees:\")\n",
    "print(sales_or_hr)\n",
    "\n",
    "# Using isin() for multiple values\n",
    "selected_depts = employees[employees['Department'].isin(['Sales', 'HR'])]\n",
    "print(\"\\nSales or HR (using isin):\")\n",
    "print(selected_depts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences: loc vs iloc\n",
    "\n",
    "| Feature | `loc` | `iloc` |\n",
    "|---------|-------|--------|\n",
    "| Uses | Labels (names) | Integer positions |\n",
    "| End inclusive? | Yes | No |\n",
    "| Example | `df.loc[0:2]` = rows 0, 1, 2 | `df.iloc[0:2]` = rows 0, 1 |\n",
    "| Columns | `df.loc[:, 'Name']` | `df.iloc[:, 0]` |\n",
    "| Best for | Named indices/columns | Position-based access |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating and Modifying Columns\n",
    "\n",
    "### Creating New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATING NEW COLUMNS =====\n",
    "# Make a copy to work with\n",
    "df = employees.copy()\n",
    "\n",
    "# Create column from calculation\n",
    "df['AnnualBonus'] = df['Salary'] * 0.1\n",
    "print(\"Added AnnualBonus column:\")\n",
    "print(df[['Name', 'Salary', 'AnnualBonus']])\n",
    "\n",
    "# Create column from multiple columns\n",
    "df['TotalCompensation'] = df['Salary'] + df['AnnualBonus']\n",
    "print(\"\\nAdded TotalCompensation column:\")\n",
    "print(df[['Name', 'Salary', 'AnnualBonus', 'TotalCompensation']])\n",
    "\n",
    "# Create column with constant value\n",
    "df['Country'] = 'Spain'\n",
    "print(\"\\nAdded Country column:\")\n",
    "print(df[['Name', 'Country']])\n",
    "\n",
    "# Create column from list\n",
    "df['EmployeeStatus'] = ['Full-time', 'Full-time', 'Part-time', 'Full-time', 'Full-time']\n",
    "print(\"\\nAdded EmployeeStatus column:\")\n",
    "print(df[['Name', 'EmployeeStatus']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Column Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONDITIONAL COLUMNS =====\n",
    "# Using np.where (similar to IF-THEN-ELSE)\n",
    "df['SalaryLevel'] = np.where(df['Salary'] >= 60000, 'High', 'Standard')\n",
    "print(\"Salary level (binary):\")\n",
    "print(df[['Name', 'Salary', 'SalaryLevel']])\n",
    "\n",
    "# Multiple conditions using np.select\n",
    "conditions = [\n",
    "    df['Salary'] >= 65000,\n",
    "    df['Salary'] >= 50000,\n",
    "    df['Salary'] < 50000\n",
    "]\n",
    "choices = ['High', 'Medium', 'Low']\n",
    "df['SalaryCategory'] = np.select(conditions, choices, default='Unknown')\n",
    "print(\"\\nSalary category (multiple levels):\")\n",
    "print(df[['Name', 'Salary', 'SalaryCategory']])\n",
    "\n",
    "# Using apply with lambda function\n",
    "df['ExperienceLevel'] = df['YearsExperience'].apply(\n",
    "    lambda x: 'Senior' if x >= 5 else 'Junior'\n",
    ")\n",
    "print(\"\\nExperience level:\")\n",
    "print(df[['Name', 'YearsExperience', 'ExperienceLevel']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Existing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MODIFYING COLUMNS =====\n",
    "df_mod = employees.copy()\n",
    "\n",
    "# Modify entire column\n",
    "df_mod['Salary'] = df_mod['Salary'] * 1.05  # 5% raise\n",
    "print(\"After 5% salary increase:\")\n",
    "print(df_mod[['Name', 'Salary']])\n",
    "\n",
    "# Modify based on condition\n",
    "df_mod.loc[df_mod['Department'] == 'IT', 'Salary'] *= 1.10  # Extra 10% for IT\n",
    "print(\"\\nAfter additional 10% for IT:\")\n",
    "print(df_mod[['Name', 'Department', 'Salary']])\n",
    "\n",
    "# Rename columns\n",
    "df_renamed = df_mod.rename(columns={'YearsExperience': 'Experience'})\n",
    "print(\"\\nRenamed column:\")\n",
    "print(df_renamed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DROPPING COLUMNS =====\n",
    "df_dropped = df.copy()\n",
    "\n",
    "# Drop a column\n",
    "df_dropped = df_dropped.drop('AnnualBonus', axis=1)\n",
    "print(\"After dropping AnnualBonus:\")\n",
    "print(df_dropped.columns)\n",
    "\n",
    "# Drop multiple columns\n",
    "df_dropped = df_dropped.drop(['Country', 'EmployeeStatus'], axis=1)\n",
    "print(\"\\nAfter dropping Country and EmployeeStatus:\")\n",
    "print(df_dropped.columns)\n",
    "\n",
    "# ===== DROPPING ROWS =====\n",
    "# Drop by index\n",
    "df_rows = employees.copy()\n",
    "df_rows = df_rows.drop([0, 1])  # Drop first two rows\n",
    "print(\"\\nAfter dropping rows 0 and 1:\")\n",
    "print(df_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Practice Exercise: Indexing and Columns\n",
    "\n",
    "Using the employees DataFrame:\n",
    "\n",
    "1. Select only employees from the 'Sales' department\n",
    "2. Create a new column called 'SalaryPerYear' that equals Salary / YearsExperience\n",
    "3. Use `loc` to get the Name and Salary of the employee at index 2\n",
    "4. Use `iloc` to get the first 3 rows and first 2 columns\n",
    "5. Create a new column 'HighPerformer' that is True if Salary > 60000, False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combining DataFrames\n",
    "\n",
    "Often you need to combine data from multiple sources. Pandas provides two main approaches:\n",
    "\n",
    "1. **`concat()`** - Stacking DataFrames (vertically or horizontally)\n",
    "2. **`merge()`** - SQL-style joins based on common columns\n",
    "\n",
    "### Concatenation\n",
    "\n",
    "Use `concat()` when you want to stack DataFrames together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONCATENATION - VERTICAL (ROWS) =====\n",
    "# Create sample DataFrames\n",
    "q1_sales = pd.DataFrame({\n",
    "    'Month': ['Jan', 'Feb', 'Mar'],\n",
    "    'Sales': [15000, 18000, 16000],\n",
    "    'Region': ['North', 'North', 'North']\n",
    "})\n",
    "\n",
    "q2_sales = pd.DataFrame({\n",
    "    'Month': ['Apr', 'May', 'Jun'],\n",
    "    'Sales': [17000, 19000, 21000],\n",
    "    'Region': ['North', 'North', 'North']\n",
    "})\n",
    "\n",
    "print(\"Q1 Sales:\")\n",
    "print(q1_sales)\n",
    "print(\"\\nQ2 Sales:\")\n",
    "print(q2_sales)\n",
    "\n",
    "# Concatenate vertically (stack rows)\n",
    "h1_sales = pd.concat([q1_sales, q2_sales], ignore_index=True)\n",
    "print(\"\\nH1 Sales (concatenated):\")\n",
    "print(h1_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONCATENATION - HORIZONTAL (COLUMNS) =====\n",
    "sales_data = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Sales': [100, 150, 120]\n",
    "})\n",
    "\n",
    "cost_data = pd.DataFrame({\n",
    "    'Cost': [60, 90, 70],\n",
    "    'Profit': [40, 60, 50]\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales_data)\n",
    "print(\"\\nCost data:\")\n",
    "print(cost_data)\n",
    "\n",
    "# Concatenate horizontally (add columns)\n",
    "combined = pd.concat([sales_data, cost_data], axis=1)\n",
    "print(\"\\nCombined (axis=1):\")\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging (Joining)\n",
    "\n",
    "Use `merge()` for SQL-style joins based on common keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATE SAMPLE DATAFRAMES FOR MERGING =====\n",
    "# Employee information\n",
    "employees_info = pd.DataFrame({\n",
    "    'EmployeeID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Carol', 'David'],\n",
    "    'DepartmentID': [10, 20, 10, 30]\n",
    "})\n",
    "\n",
    "# Department information\n",
    "departments = pd.DataFrame({\n",
    "    'DepartmentID': [10, 20, 30, 40],\n",
    "    'DepartmentName': ['Sales', 'IT', 'HR', 'Finance'],\n",
    "    'Location': ['Madrid', 'Barcelona', 'Valencia', 'Seville']\n",
    "})\n",
    "\n",
    "print(\"Employees:\")\n",
    "print(employees_info)\n",
    "print(\"\\nDepartments:\")\n",
    "print(departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INNER JOIN (DEFAULT) =====\n",
    "# Keep only matching rows from both DataFrames\n",
    "inner_merged = pd.merge(employees_info, departments, on='DepartmentID', how='inner')\n",
    "print(\"Inner Join (default):\")\n",
    "print(inner_merged)\n",
    "print(f\"\\nRows: {len(inner_merged)} (only matching DepartmentIDs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LEFT JOIN =====\n",
    "# Keep all rows from left DataFrame, matching from right\n",
    "left_merged = pd.merge(employees_info, departments, on='DepartmentID', how='left')\n",
    "print(\"Left Join:\")\n",
    "print(left_merged)\n",
    "print(f\"\\nRows: {len(left_merged)} (all employees kept)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RIGHT JOIN =====\n",
    "# Keep all rows from right DataFrame, matching from left\n",
    "right_merged = pd.merge(employees_info, departments, on='DepartmentID', how='right')\n",
    "print(\"Right Join:\")\n",
    "print(right_merged)\n",
    "print(f\"\\nRows: {len(right_merged)} (all departments kept)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OUTER JOIN =====\n",
    "# Keep all rows from both DataFrames\n",
    "outer_merged = pd.merge(employees_info, departments, on='DepartmentID', how='outer')\n",
    "print(\"Outer Join:\")\n",
    "print(outer_merged)\n",
    "print(f\"\\nRows: {len(outer_merged)} (all employees and departments)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MERGING ON DIFFERENT COLUMN NAMES =====\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Value1': [10, 20, 30]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Code': [1, 2, 3],\n",
    "    'Value2': [100, 200, 300]\n",
    "})\n",
    "\n",
    "merged = pd.merge(df1, df2, left_on='ID', right_on='Code')\n",
    "print(\"Merge on different column names:\")\n",
    "print(merged)\n",
    "\n",
    "# ===== MERGING ON MULTIPLE COLUMNS =====\n",
    "df1 = pd.DataFrame({\n",
    "    'Year': [2023, 2023, 2024],\n",
    "    'Quarter': ['Q1', 'Q2', 'Q1'],\n",
    "    'Sales': [100, 150, 120]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Year': [2023, 2023, 2024],\n",
    "    'Quarter': ['Q1', 'Q2', 'Q1'],\n",
    "    'Costs': [60, 90, 70]\n",
    "})\n",
    "\n",
    "merged_multi = pd.merge(df1, df2, on=['Year', 'Quarter'])\n",
    "print(\"\\nMerge on multiple columns:\")\n",
    "print(merged_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Joins\n",
    "\n",
    "| Join Type | Parameter | Description | Use When |\n",
    "|-----------|-----------|-------------|----------|\n",
    "| Inner | `how='inner'` | Only matching rows | You want intersection |\n",
    "| Left | `how='left'` | All from left + matching from right | Keep all from main table |\n",
    "| Right | `how='right'` | All from right + matching from left | Keep all from lookup table |\n",
    "| Outer | `how='outer'` | All rows from both | Keep everything |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced: GroupBy Operations\n",
    "\n",
    "The `groupby()` method is one of Pandas' most powerful features. It follows the **split-apply-combine** pattern:\n",
    "\n",
    "1. **Split** - Divide data into groups based on a column\n",
    "2. **Apply** - Perform a calculation on each group\n",
    "3. **Combine** - Combine results into a DataFrame\n",
    "\n",
    "### Basic GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATE SAMPLE DATA =====\n",
    "sales = pd.DataFrame({\n",
    "    'Region': ['North', 'South', 'North', 'South', 'North', 'South', 'East', 'East'],\n",
    "    'Product': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'A'],\n",
    "    'Sales': [100, 150, 120, 180, 110, 160, 140, 130],\n",
    "    'Quantity': [10, 15, 12, 18, 11, 16, 14, 13]\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GROUP BY SINGLE COLUMN =====\n",
    "# Total sales by region\n",
    "region_sales = sales.groupby('Region')['Sales'].sum()\n",
    "print(\"Total sales by region:\")\n",
    "print(region_sales)\n",
    "print(f\"\\nType: {type(region_sales)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "region_sales_df = sales.groupby('Region')['Sales'].sum().reset_index()\n",
    "print(\"\\nAs DataFrame:\")\n",
    "print(region_sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MULTIPLE AGGREGATIONS =====\n",
    "# Multiple statistics for each group\n",
    "region_stats = sales.groupby('Region')['Sales'].agg(['sum', 'mean', 'count', 'min', 'max'])\n",
    "print(\"Multiple aggregations by region:\")\n",
    "print(region_stats)\n",
    "\n",
    "# Rename columns\n",
    "region_stats_renamed = sales.groupby('Region')['Sales'].agg([\n",
    "    ('Total', 'sum'),\n",
    "    ('Average', 'mean'),\n",
    "    ('Count', 'count')\n",
    "])\n",
    "print(\"\\nWith renamed columns:\")\n",
    "print(region_stats_renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GROUP BY MULTIPLE COLUMNS =====\n",
    "# Sales by region AND product\n",
    "region_product = sales.groupby(['Region', 'Product'])['Sales'].sum()\n",
    "print(\"Sales by Region and Product:\")\n",
    "print(region_product)\n",
    "\n",
    "# Reset index for easier viewing\n",
    "region_product_df = sales.groupby(['Region', 'Product'])['Sales'].sum().reset_index()\n",
    "print(\"\\nAs DataFrame:\")\n",
    "print(region_product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== AGGREGATING MULTIPLE COLUMNS =====\n",
    "# Different aggregations for different columns\n",
    "summary = sales.groupby('Region').agg({\n",
    "    'Sales': ['sum', 'mean'],\n",
    "    'Quantity': ['sum', 'mean']\n",
    "})\n",
    "print(\"Multiple columns with multiple aggregations:\")\n",
    "print(summary)\n",
    "\n",
    "# Flatten column names\n",
    "summary.columns = ['_'.join(col) for col in summary.columns]\n",
    "print(\"\\nWith flattened column names:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced GroupBy Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FILTERING GROUPS =====\n",
    "# Keep only groups where total sales > 200\n",
    "high_sales_regions = sales.groupby('Region').filter(lambda x: x['Sales'].sum() > 200)\n",
    "print(\"Regions with total sales > 200:\")\n",
    "print(high_sales_regions)\n",
    "\n",
    "# ===== TRANSFORMING WITHIN GROUPS =====\n",
    "# Add a column with group mean\n",
    "sales['RegionAvg'] = sales.groupby('Region')['Sales'].transform('mean')\n",
    "print(\"\\nWith region average:\")\n",
    "print(sales[['Region', 'Sales', 'RegionAvg']])\n",
    "\n",
    "# Calculate deviation from group mean\n",
    "sales['DeviationFromAvg'] = sales['Sales'] - sales['RegionAvg']\n",
    "print(\"\\nWith deviation from average:\")\n",
    "print(sales[['Region', 'Sales', 'RegionAvg', 'DeviationFromAvg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CUSTOM AGGREGATION FUNCTIONS =====\n",
    "# Define custom function\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "# Apply custom function\n",
    "sales_range = sales.groupby('Region')['Sales'].agg([\n",
    "    'mean',\n",
    "    ('range', range_func),\n",
    "    ('std', 'std')\n",
    "])\n",
    "print(\"Custom aggregation:\")\n",
    "print(sales_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PIVOT TABLES (ANOTHER WAY TO GROUP) =====\n",
    "# Create a pivot table (like Excel)\n",
    "pivot = sales.pivot_table(\n",
    "    values='Sales',\n",
    "    index='Region',\n",
    "    columns='Product',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(\"Pivot table:\")\n",
    "print(pivot)\n",
    "\n",
    "# With margins (totals)\n",
    "pivot_margins = sales.pivot_table(\n",
    "    values='Sales',\n",
    "    index='Region',\n",
    "    columns='Product',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True\n",
    ")\n",
    "print(\"\\nPivot table with totals:\")\n",
    "print(pivot_margins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Practice Exercise: Combining and GroupBy\n",
    "\n",
    "Create two DataFrames and practice combining and grouping:\n",
    "\n",
    "```python\n",
    "orders = pd.DataFrame({\n",
    "    'OrderID': [1, 2, 3, 4, 5],\n",
    "    'CustomerID': [101, 102, 101, 103, 102],\n",
    "    'Amount': [250, 180, 300, 150, 220]\n",
    "})\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'CustomerID': [101, 102, 103],\n",
    "    'Name': ['Alice', 'Bob', 'Carol'],\n",
    "    'City': ['Madrid', 'Barcelona', 'Valencia']\n",
    "})\n",
    "```\n",
    "\n",
    "Tasks:\n",
    "1. Merge the orders and customers DataFrames\n",
    "2. Calculate total amount spent by each customer using groupby\n",
    "3. Calculate average order amount by city\n",
    "4. Find the city with the highest total sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! ðŸŽ‰\n",
    "\n",
    "You've completed the Pandas basics tutorial! You now understand:\n",
    "\n",
    "âœ… **Series vs DataFrame** - The two main Pandas data structures  \n",
    "âœ… **Creating data** - From lists, dicts, and files  \n",
    "âœ… **Reading/Writing CSV** - Loading and saving data  \n",
    "âœ… **Basic operations** - describe(), filtering, statistics  \n",
    "âœ… **Indexing** - loc (label-based) and iloc (position-based)  \n",
    "âœ… **Creating columns** - New columns, conditional logic  \n",
    "âœ… **Combining DataFrames** - merge() and concat()  \n",
    "âœ… **GroupBy** - Split-apply-combine for aggregations  \n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Now that you know Pandas, you're ready for:\n",
    "- **Data visualization** with Matplotlib and Seaborn\n",
    "- **Exploratory Data Analysis (EDA)** on real datasets\n",
    "- **Machine Learning** with scikit-learn\n",
    "- **Advanced Pandas** - Multi-indexing, time series, reshaping\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Series = single column, DataFrame = table**\n",
    "2. **Use `loc` for labels, `iloc` for positions**\n",
    "3. **`merge()` for SQL-style joins, `concat()` for stacking**\n",
    "4. **`groupby()` is your friend for aggregations**\n",
    "5. **Always use `describe()` and `info()` when exploring new data**\n",
    "\n",
    "Keep practicing with real datasets! ðŸ“Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
