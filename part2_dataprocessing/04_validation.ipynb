{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Model Validation (Hands-on with KNN)\n",
        "\n",
        "This notebook practices the validation concepts from class with very simple code.\n",
        "\n",
        "Goals:\n",
        "- Understand why validation is needed (overfitting).\n",
        "- Build train/test splits manually (including stratification).\n",
        "- Build train/validation/test splits for hyperparameter tuning.\n",
        "- Implement k-fold and leave-one-out validation manually.\n",
        "- Use `KNeighborsClassifier` with toy datasets from `sklearn.datasets`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Imports and helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.datasets import load_iris, make_moons\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "np.set_printoptions(suppress=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy_manual(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return (y_true == y_pred).mean()\n",
        "\n",
        "\n",
        "def class_percentages(y):\n",
        "    y = np.array(y)\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    percentages = 100 * counts / len(y)\n",
        "    return pd.DataFrame({\n",
        "        'class': classes,\n",
        "        'count': counts,\n",
        "        'percentage': percentages.round(2)\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Why validation: train accuracy vs test accuracy (overfitting intuition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_test_split_manual(X, y, test_size=0.2, seed=42, stratify=False):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = len(y)\n",
        "\n",
        "    if not stratify:\n",
        "        indices = np.arange(n)\n",
        "        rng.shuffle(indices)\n",
        "\n",
        "        n_test = int(round(test_size * n))\n",
        "        test_idx = indices[:n_test]\n",
        "        train_idx = indices[n_test:]\n",
        "    else:\n",
        "        train_idx = []\n",
        "        test_idx = []\n",
        "\n",
        "        for cls in np.unique(y):\n",
        "            cls_idx = np.where(y == cls)[0]\n",
        "            rng.shuffle(cls_idx)\n",
        "\n",
        "            n_cls_test = int(round(test_size * len(cls_idx)))\n",
        "            test_idx.extend(cls_idx[:n_cls_test])\n",
        "            train_idx.extend(cls_idx[n_cls_test:])\n",
        "\n",
        "        train_idx = np.array(train_idx)\n",
        "        test_idx = np.array(test_idx)\n",
        "\n",
        "        rng.shuffle(train_idx)\n",
        "        rng.shuffle(test_idx)\n",
        "\n",
        "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Toy dataset with some noise\n",
        "X_moons, y_moons = make_moons(n_samples=300, noise=0.28, random_state=7)\n",
        "\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split_manual(\n",
        "    X_moons, y_moons, test_size=0.30, seed=7, stratify=True\n",
        ")\n",
        "\n",
        "results = []\n",
        "for k in [1, 3, 15, 35]:\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train_m, y_train_m)\n",
        "\n",
        "    train_pred = model.predict(X_train_m)\n",
        "    test_pred = model.predict(X_test_m)\n",
        "\n",
        "    results.append({\n",
        "        'k': k,\n",
        "        'train_accuracy': round(accuracy_manual(y_train_m, train_pred), 4),\n",
        "        'test_accuracy': round(accuracy_manual(y_test_m, test_pred), 4)\n",
        "    })\n",
        "\n",
        "pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional visualization (helps understand overfitting intuition)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, s=20, cmap='coolwarm')\n",
        "plt.title('Toy dataset: make_moons')\n",
        "plt.xlabel('feature 1')\n",
        "plt.ylabel('feature 2')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1\n",
        "Change `test_size`, `seed`, and `k` values above.\n",
        "\n",
        "Questions:\n",
        "- Which `k` gives very high train accuracy but lower test accuracy?\n",
        "- Do your conclusions change when you change the random seed?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train/Test split details: randomness, reproducibility, proportion, stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "print('Dataset size:', len(y_iris))\n",
        "print('Class names:', list(target_names))\n",
        "class_percentages(y_iris)\n",
        "\n",
        "# Use only to first features for a more complex dataset\n",
        "X_iris = X_iris[:, :2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split without stratification\n",
        "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split_manual(\n",
        "    X_iris, y_iris, test_size=0.20, seed=3, stratify=False\n",
        ")\n",
        "\n",
        "print('Without stratification - train class distribution')\n",
        "display(class_percentages(y_train_ns))\n",
        "print('Without stratification - test class distribution')\n",
        "display(class_percentages(y_test_ns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split with stratification\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split_manual(\n",
        "    X_iris, y_iris, test_size=0.20, seed=3, stratify=True\n",
        ")\n",
        "\n",
        "print('With stratification - train class distribution')\n",
        "display(class_percentages(y_train_s))\n",
        "print('With stratification - test class distribution')\n",
        "display(class_percentages(y_test_s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train one KNN model with the non-stratified split\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_ns, y_train_ns)\n",
        "\n",
        "y_pred_train = knn.predict(X_train_ns)\n",
        "y_pred_test = knn.predict(X_test_ns)\n",
        "\n",
        "print('Train accuracy:', round(accuracy_manual(y_train_ns, y_pred_train), 4))\n",
        "print('Test accuracy :', round(accuracy_manual(y_test_ns, y_pred_test), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f93c095",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train one KNN model with the stratified split\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_s, y_train_s)\n",
        "\n",
        "y_pred_train = knn.predict(X_train_s)\n",
        "y_pred_test = knn.predict(X_test_s)\n",
        "\n",
        "print('Train accuracy:', round(accuracy_manual(y_train_s, y_pred_train), 4))\n",
        "print('Test accuracy :', round(accuracy_manual(y_test_s, y_pred_test), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2\n",
        "Try these changes and rerun:\n",
        "- `test_size=0.30`\n",
        "- `seed=10`\n",
        "- `n_neighbors` in KNN as 1, 3, 7, 11\n",
        "\n",
        "Write one short conclusion: which setting seems more stable?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Split into Train / Validation / Test (for hyperparameter tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_val_test_split_manual(X, y, val_size=0.20, test_size=0.20, seed=42, stratify=True):\n",
        "    # First split: separate test set\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split_manual(\n",
        "        X, y, test_size=test_size, seed=seed, stratify=stratify\n",
        "    )\n",
        "\n",
        "    # Second split: split train_val into train and validation\n",
        "    # val_size is relative to the original full dataset\n",
        "    val_relative = val_size / (1 - test_size)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split_manual(\n",
        "        X_train_val, y_train_val, test_size=val_relative, seed=seed + 1, stratify=stratify\n",
        "    )\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split_manual(\n",
        "    X_iris, y_iris, val_size=0.20, test_size=0.20, seed=8, stratify=True\n",
        ")\n",
        "\n",
        "print('Sizes -> train:', len(y_train), 'val:', len(y_val), 'test:', len(y_test))\n",
        "print('Train distribution')\n",
        "display(class_percentages(y_train))\n",
        "print('Validation distribution')\n",
        "display(class_percentages(y_val))\n",
        "print('Test distribution')\n",
        "display(class_percentages(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning using validation set only\n",
        "candidate_k = [1, 3, 5, 7, 9, 11, 13]\n",
        "val_results = []\n",
        "\n",
        "for k in candidate_k:\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "    val_pred = model.predict(X_val)\n",
        "\n",
        "    val_results.append({\n",
        "        'k': k,\n",
        "        'validation_accuracy': round(accuracy_manual(y_val, val_pred), 4)\n",
        "    })\n",
        "\n",
        "val_df = pd.DataFrame(val_results).sort_values('validation_accuracy', ascending=False)\n",
        "val_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_k = int(val_df.iloc[0]['k'])\n",
        "print('Best k selected on validation:', best_k)\n",
        "\n",
        "# Final model: train with train+validation, evaluate once on test\n",
        "X_train_final = np.vstack([X_train, X_val])\n",
        "y_train_final = np.concatenate([y_train, y_val])\n",
        "\n",
        "final_model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "final_model.fit(X_train_final, y_train_final)\n",
        "test_pred = final_model.predict(X_test)\n",
        "\n",
        "print('Final test accuracy:', round(accuracy_manual(y_test, test_pred), 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3\n",
        "Change `candidate_k` and split proportions.\n",
        "\n",
        "Questions:\n",
        "- Does the selected `best_k` change?\n",
        "- Is test accuracy always the same as validation accuracy? Why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Manual K-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_stratified_folds(y, n_folds=5, seed=42):\n",
        "    y = np.array(y)\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    folds = [[] for _ in range(n_folds)]\n",
        "\n",
        "    for cls in np.unique(y):\n",
        "        cls_idx = np.where(y == cls)[0]\n",
        "        rng.shuffle(cls_idx)\n",
        "\n",
        "        # Round-robin assignment keeps class proportions balanced\n",
        "        for i, idx in enumerate(cls_idx):\n",
        "            fold_id = i % n_folds\n",
        "            folds[fold_id].append(idx)\n",
        "\n",
        "    return [np.array(fold, dtype=int) for fold in folds]\n",
        "\n",
        "\n",
        "def k_fold_cv_knn(X, y, n_neighbors=5, n_folds=5, seed=42):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    folds = make_stratified_folds(y, n_folds=n_folds, seed=seed)\n",
        "    fold_scores = []\n",
        "\n",
        "    for fold_id in range(n_folds):\n",
        "        val_idx = folds[fold_id]\n",
        "\n",
        "        train_parts = [folds[i] for i in range(n_folds) if i != fold_id]\n",
        "        train_idx = np.concatenate(train_parts)\n",
        "\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "        model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        fold_acc = accuracy_manual(y_val, y_val_pred)\n",
        "        fold_scores.append(fold_acc)\n",
        "\n",
        "    return np.array(fold_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split_manual(\n",
        "    X_iris, y_iris, test_size=0.20, seed=2, stratify=True\n",
        ")\n",
        "\n",
        "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
        "cv_rows = []\n",
        "\n",
        "for k in k_values:\n",
        "    scores = k_fold_cv_knn(X_train, y_train, n_neighbors=k, n_folds=5, seed=4)\n",
        "    cv_rows.append({\n",
        "        'k': k,\n",
        "        'fold_scores': np.round(scores, 4),\n",
        "        'mean_cv_accuracy': round(scores.mean(), 4),\n",
        "        'std_cv_accuracy': round(scores.std(), 4),\n",
        "    })\n",
        "\n",
        "cv_df = pd.DataFrame(cv_rows).sort_values('mean_cv_accuracy', ascending=False)\n",
        "cv_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(cv_df['k'], cv_df['mean_cv_accuracy'], marker='o')\n",
        "plt.title('5-fold CV mean accuracy vs k')\n",
        "plt.xlabel('k (neighbors)')\n",
        "plt.ylabel('mean CV accuracy')\n",
        "# plt.ylim(0.70, 0.85)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45158d89",
      "metadata": {},
      "source": [
        "#### Precision of CV estimates compared to test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e474683",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698d166e",
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_rows = []\n",
        "for n_folds in [2, 5, 10, 20, 40]:\n",
        "    scores = k_fold_cv_knn(X_train, y_train, n_neighbors=11, n_folds=n_folds, seed=4)\n",
        "    test_pred = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train).predict(X_test)\n",
        "    test_accuracy = accuracy_manual(y_test, test_pred)\n",
        "    cv_rows.append({\n",
        "        'n_folds': n_folds,\n",
        "        'fold_scores': np.round(scores, 4),\n",
        "        'mean_cv_accuracy': round(scores.mean(), 4),\n",
        "        'std_cv_accuracy': round(scores.std(), 4),\n",
        "        'test_accuracy': test_accuracy\n",
        "    })\n",
        "\n",
        "cv_df = pd.DataFrame(cv_rows).sort_values('n_folds', ascending=True)\n",
        "cv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8185eae8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4\n",
        "- Change `n_folds` from 5 to 3 and 10.\n",
        "- Change `seed`.\n",
        "\n",
        "Questions:\n",
        "- Which `k` is most stable (high mean, low std)?\n",
        "- How do results compare to one train/test split?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Leave-One-Out Cross-Validation (LOO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def leave_one_out_cv_knn(X, y, n_neighbors=5):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    n = len(y)\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        train_idx = np.array([j for j in range(n) if j != i])\n",
        "        test_idx = i\n",
        "\n",
        "        model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        model.fit(X[train_idx], y[train_idx])\n",
        "\n",
        "        pred = model.predict(X[test_idx:test_idx+1])[0]\n",
        "        if pred == y[test_idx]:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use a subset to keep runtime small for beginners\n",
        "\n",
        "comparison_rows = []\n",
        "for k in [1, 3, 5, 7, 9, 11]:\n",
        "    loo_acc = leave_one_out_cv_knn(X_train, y_train, n_neighbors=k)\n",
        "    k5_acc = k_fold_cv_knn(X_train, y_train, n_neighbors=k, n_folds=5, seed=12).mean()\n",
        "    k10_acc = k_fold_cv_knn(X_train, y_train, n_neighbors=k, n_folds=10, seed=12).mean()\n",
        "    test_pred = KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train).predict(X_test)\n",
        "    test_accuracy = accuracy_manual(y_test, test_pred)\n",
        "\n",
        "    comparison_rows.append({\n",
        "        'k': k,\n",
        "        'loo_accuracy': round(loo_acc, 4),\n",
        "        '5fold_accuracy': round(k5_acc, 4),\n",
        "        '10fold_accuracy': round(k10_acc, 4),\n",
        "        'test_accuracy': round(test_accuracy, 4)\n",
        "    })\n",
        "\n",
        "pd.DataFrame(comparison_rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5\n",
        "- Increase subset size from 60 to 100.\n",
        "- Time the execution of LOO and 5-fold CV using `%time`.\n",
        "\n",
        "Questions:\n",
        "- Which method is slower?\n",
        "- Are LOO and 5-fold results very different?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Optional: Manual one-hot encoding (without sklearn)\n",
        "This is a small extra example to keep preprocessing transparent for beginners.\n",
        "\n",
        "The function `one_hot_encode_manual` takes a DataFrame and a column name, and creates new binary columns for each category in that column. By default, it excludes the last category to avoid multicollinearity (the \"dummy variable trap\"). You can change this behavior with the `exclude_last` parameter.\n",
        "\n",
        "#### When to exclude the last category?\n",
        "- If you are using linear models (like linear regression or logistic regression), you should exclude one category to avoid multicollinearity.\n",
        "- If you are using tree-based models (like decision trees or random forests), you can include all categories since these models are not affected by multicollinearity.\n",
        "- On KNN, we want to include all categories so distances are calculated equally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_encode_manual(df, column, exclude_last=True):\n",
        "    df = df.copy()\n",
        "    categories = sorted(df[column].unique())\n",
        "    if len(categories) < 2:\n",
        "        raise ValueError(\"Column must have at least 2 unique categories for one-hot encoding.\")\n",
        "\n",
        "    # If exclude_last is True, we encode all but the last category to avoid multicollinearity\n",
        "    categories_to_encode = categories[:-1] if exclude_last else categories  \n",
        "\n",
        "    for cat in categories_to_encode:\n",
        "        new_col = f'{column}_{cat}'\n",
        "        df[new_col] = (df[column] == cat).astype(int)\n",
        "\n",
        "    df = df.drop(columns=[column])\n",
        "    return df\n",
        "\n",
        "\n",
        "toy_df = pd.DataFrame({\n",
        "    'size': ['small', 'medium', 'small', 'large', 'medium'],\n",
        "    'price': [10, 15, 12, 20, 18]\n",
        "})\n",
        "\n",
        "print('Original:')\n",
        "display(toy_df)\n",
        "\n",
        "print('One-hot encoded manually:')\n",
        "display(one_hot_encode_manual(toy_df, 'size'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusions\n",
        "- A single train/test split is simple, but can depend on randomness.\n",
        "- Train/validation/test helps tune hyperparameters more safely.\n",
        "- K-fold CV is usually more robust than one split.\n",
        "- Leave-One-Out is informative but can be expensive.\n",
        "- Manual implementations help understand each validation step clearly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16fa18f3",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
